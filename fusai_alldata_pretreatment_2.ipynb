{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import functools\n",
    "from datetime import *\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#开始构造训练集和测试集\n",
    "chusai_QY_xinxi_train_df = pd.read_csv('../../chusai/data/train/企业基本信息&高管信息&投资信息.csv')\n",
    "chusai_QY_xinxi_train_df['is_chusai'] = 1\n",
    "fusai_QY_xinxi_train_df = pd.read_csv('../data/train/企业基本信息&高管信息&投资信息.csv')\n",
    "fusai_QY_xinxi_train_df['is_chusai'] = 0\n",
    "QY_xinxi_train_df = pd.concat([chusai_QY_xinxi_train_df, fusai_QY_xinxi_train_df])\n",
    "QY_xinxi_train_df.rename(columns={'企业名称':'qymc', '注册号':'zch', '统一社会信用代码':'tyshxydm', '注册资金':'zczj', '注册资本(金)币种名称':'zczbbzmc', \n",
    "                                  '企业(机构)类型名称':'qyjglxmc', '行业门类代码':'hymldm', '成立日期':'clrq', '核准日期':'hzrq', '住所所在地省份':'zsszdsf', \n",
    "                                  '姓名':'xm', '法定代表人标志':'fddbrbz', '首席代表标志':'sxdbbz', '职务':'zw', '投资人':'tzr', '出资比例':'czbl'}, inplace=True)\n",
    "train_df = QY_xinxi_train_df[['qymc', 'zch', 'tyshxydm', 'zczj', 'zczbbzmc', 'qyjglxmc', 'hymldm', 'clrq', 'hzrq', 'zsszdsf', 'is_chusai']]\n",
    "train_df.drop_duplicates(['qymc'], keep='first', inplace=True)\n",
    "\n",
    "QY_xinxi_test_df = pd.read_csv('../data/test/企业基本信息&高管信息&投资信息.csv')\n",
    "QY_xinxi_test_df.rename(columns={'企业名称':'qymc', '注册号':'zch', '统一社会信用代码':'tyshxydm', '注册资金':'zczj', '注册资本(金)币种名称':'zczbbzmc', \n",
    "                                  '企业(机构)类型名称':'qyjglxmc', '行业门类代码':'hymldm', '成立日期':'clrq', '核准日期':'hzrq', '住所所在地省份':'zsszdsf', \n",
    "                                  '姓名':'xm', '法定代表人标志':'fddbrbz', '首席代表标志':'sxdbbz', '职务':'zw', '投资人':'tzr', '出资比例':'czbl'}, inplace=True)\n",
    "test_df = QY_xinxi_test_df[['qymc', 'zch', 'tyshxydm', 'zczj', 'zczbbzmc', 'qyjglxmc', 'hymldm', 'clrq', 'hzrq', 'zsszdsf']]\n",
    "test_df.drop_duplicates(['qymc'], keep='first', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#开始给训练集打标签\n",
    "#是否失信\n",
    "chusai_SXQY_train_df = pd.read_csv('../../chusai/data/train/失信被执行人名单.csv')\n",
    "fusai_SXQY_train_df = pd.read_csv('../data/train/失信被执行人名单.csv')\n",
    "SXQY_train_df = pd.concat([chusai_SXQY_train_df, fusai_SXQY_train_df])\n",
    "SXQY_train_df.rename(columns={'企业名称':'qymc'}, inplace=True)\n",
    "SXQY_set = set(SXQY_train_df['qymc'])\n",
    "train_df['is_shixin'] = train_df['qymc'].map(lambda x : 1 if x in SXQY_set else 0)\n",
    "\n",
    "#是否处罚\n",
    "chusai_SGS_FRCF_train_df = pd.read_csv('../../chusai/data/train/双公示-法人行政处罚信息.csv')\n",
    "fusai_SGS_FRCF_train_df = pd.read_csv('../data/train/双公示-法人行政处罚信息.csv')\n",
    "SGS_FRCF_train_df = pd.concat([chusai_SGS_FRCF_train_df, fusai_SGS_FRCF_train_df])\n",
    "SGS_FRCF_train_df.rename(columns={'企业名称':'qymc'}, inplace=True)\n",
    "SGS_FRCF_set = set(SGS_FRCF_train_df['qymc'])\n",
    "train_df['is_chufa'] = train_df['qymc'].map(lambda x : 1 if x in SGS_FRCF_set else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "#开始统计跟出资比例相关的统计特征\n",
    "def get_QY_czbl_statistic_fea(df, QY_df):\n",
    "    temp_pivot_table = pd.pivot_table(QY_df, index='qymc', values='czbl', aggfunc={np.max, np.mean, np.min, np.std})\n",
    "    temp_pivot_table.reset_index(inplace=True)\n",
    "    temp_pivot_table.rename(columns={'amax':'czbl_max', 'amin':'czbl_min', 'mean':'czbl_mean', 'std':'czbl_std'}, inplace=True)\n",
    "    df = pd.merge(df, temp_pivot_table, on='qymc', how='left')\n",
    "    return df\n",
    "    \n",
    "train_df = get_QY_czbl_statistic_fea(train_df, QY_xinxi_train_df)\n",
    "test_df = get_QY_czbl_statistic_fea(test_df, QY_xinxi_test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "#定义获取两列时间差函数\n",
    "def get_deltaDay(df, col1, col2):\n",
    "    col1 = df[col1]\n",
    "    col2 = df[col2]\n",
    "    if (col1 is np.nan) | (col2 is np.nan) | (col1 == -1) | (col2 == -1):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return (col2 - col1).days\n",
    "\n",
    "#开始处理跟企业成立日期，核准日期相关的特征\n",
    "def get_QY_clhzrq_feature(df):\n",
    "    df['clrq'] = df['clrq'].map(lambda x : np.nan if x is np.nan else pd.to_datetime(str(x)[:10]))\n",
    "    df['hzrq'] = df['hzrq'].map(lambda x : np.nan if x is np.nan else pd.to_datetime(str(x)[:10]))\n",
    "    df['clrq_year'] = df['clrq'].map(lambda x : np.nan if x is np.nan else x.year)\n",
    "    df['clrq_month'] = df['clrq'].map(lambda x : np.nan if x is np.nan else x.month)\n",
    "    df['clrq_day'] = df['clrq'].map(lambda x : np.nan if x is np.nan else x.day)\n",
    "    df['hzrq_year'] = df['hzrq'].map(lambda x : np.nan if x is np.nan else x.year)\n",
    "    df['hzrq_month'] = df['hzrq'].map(lambda x : np.nan if x is np.nan else x.month)\n",
    "    df['hzrq_day'] = df['hzrq'].map(lambda x : np.nan if x is np.nan else x.day)\n",
    "    f = functools.partial(get_deltaDay, col1='clrq', col2='hzrq')\n",
    "    df['clhz_deltaDay'] = df.apply(f, axis=1)\n",
    "    return df\n",
    "\n",
    "train_df = get_QY_clhzrq_feature(train_df)\n",
    "test_df = get_QY_clhzrq_feature(test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "#开始统计投资人个数特征\n",
    "def get_QY_tzrgs_feature(df, QY_xinxi_df):\n",
    "    QY_xinxi_df_cpoy = QY_xinxi_df.copy()\n",
    "    QY_xinxi_df_cpoy.drop_duplicates(['qymc', 'tzr'], inplace=True)\n",
    "    temp_pivot_table = pd.pivot_table(QY_xinxi_df_cpoy, index='qymc', values='tzr', aggfunc=len)\n",
    "    temp_pivot_table.reset_index(inplace=True)\n",
    "    temp_pivot_table.rename(columns={'tzr':'QY_tzrgs'}, inplace=True)\n",
    "    df = pd.merge(df, temp_pivot_table, on='qymc', how='left')\n",
    "    return df\n",
    "\n",
    "train_df = get_QY_tzrgs_feature(train_df, QY_xinxi_train_df)\n",
    "test_df = get_QY_tzrgs_feature(test_df, QY_xinxi_test_df)\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "#开始统计职务种类数特征\n",
    "def get_QY_zwzls_feature(df, QY_xinxi_df):\n",
    "    QY_xinxi_df_cpoy = QY_xinxi_df.copy()\n",
    "    QY_xinxi_df_cpoy.drop_duplicates(['qymc', 'zw'], inplace=True)\n",
    "    temp_pivot_table = pd.pivot_table(QY_xinxi_df_cpoy, index='qymc', values='zw', aggfunc=len)\n",
    "    temp_pivot_table.reset_index(inplace=True)\n",
    "    temp_pivot_table.rename(columns={'zw':'QY_zwzls'}, inplace=True)\n",
    "    df = pd.merge(df, temp_pivot_table, on='qymc', how='left')\n",
    "    return df\n",
    "\n",
    "train_df = get_QY_zwzls_feature(train_df, QY_xinxi_train_df)\n",
    "test_df = get_QY_zwzls_feature(test_df, QY_xinxi_test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "#开始统计法定代表人个数，首席代表个数\n",
    "def get_QY_dbgs_feature(df, QY_xinxi_df):\n",
    "    for fea in ['fddbrbz', 'sxdbbz']:\n",
    "        temp = QY_xinxi_df[QY_xinxi_df[fea] == '是']\n",
    "        temp_pivot_table = pd.pivot_table(temp, index='qymc', values=fea, aggfunc=len)\n",
    "        temp_pivot_table.reset_index(inplace=True)\n",
    "        temp_pivot_table.rename(columns={fea:'QY_' + fea + '_gs'}, inplace=True)\n",
    "        df = pd.merge(df, temp_pivot_table, on='qymc', how='left')\n",
    "    return df\n",
    "    \n",
    "train_df = get_QY_dbgs_feature(train_df, QY_xinxi_train_df)\n",
    "test_df = get_QY_dbgs_feature(test_df, QY_xinxi_test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               qymc                               zch  \\\n",
      "0  B1F44D639BCF516C32ECA487191A326E  8B8209E9A0CDDD6CB57946246640DA7A   \n",
      "1  0A88930D50370898305523BB246E61A0  326D7D5D220E124BC3A76731C1A36014   \n",
      "2  514F18D6CD172C4CEE7783452AC888D3  157113A7964636EA2BC561CA2ABB2563   \n",
      "3  F7772F4ECF538C105C462D428E5738CE  F712A0911330E501A6ABFF933684A8EC   \n",
      "4  DF84E7392334D435F5751D12E73CA9EE  37F24B7391B5BB6E656AF79FEDB356CD   \n",
      "\n",
      "                           tyshxydm     zczj zczbbzmc  \\\n",
      "0  14A6CB760956748775EAF0ECF0B2BBCA  16930.0       美元   \n",
      "1  8F33C74B984141F443B9364F8446F4E4    670.0       美元   \n",
      "2  90971347F1A1250919356393B9F966B6      0.0     人民币元   \n",
      "3  5B7E519CFE95F79BFFD4AA840B1BFE80   1220.0       美元   \n",
      "4  90971347F1A1250919356393B9F966B6  11200.0       美元   \n",
      "\n",
      "                           qyjglxmc hymldm       clrq       hzrq zsszdsf  \\\n",
      "0  8E6EF155A976DC028A570C3B2920760B      C 2011-04-11 2017-09-01     江苏省   \n",
      "1  E75CEE42A60D18E77DFF67B7429D32D2      C 2004-07-05 2017-12-25     江苏省   \n",
      "2  CFE2148078C633DD8F91BD94D6C08173      L 2006-03-13 2006-03-13     江苏省   \n",
      "3  B395FD4D222405CDF7678DF19451A08D      C 2001-12-30 2016-11-28     江苏省   \n",
      "4  B395FD4D222405CDF7678DF19451A08D      C 2006-07-10 2015-06-04     江苏省   \n",
      "\n",
      "      ...       clrq_day  hzrq_year  hzrq_month  hzrq_day  clhz_deltaDay  \\\n",
      "0     ...           11.0       2017           9         1         2335.0   \n",
      "1     ...            5.0       2017          12        25         4921.0   \n",
      "2     ...           13.0       2006           3        13            0.0   \n",
      "3     ...           30.0       2016          11        28         5447.0   \n",
      "4     ...           10.0       2015           6         4         3251.0   \n",
      "\n",
      "   QY_tzrgs  QY_zwzls  QY_fddbrbz_gs  QY_sxdbbz_gs  QYJL_number  \n",
      "0         2         5            2.0           NaN           12  \n",
      "1         2         1            2.0           NaN            2  \n",
      "2         1         1            1.0           1.0            1  \n",
      "3         1         5            1.0           NaN            7  \n",
      "4         1         6            1.0           NaN           11  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "#初步统计企业信息记录数\n",
    "def get_QYJL_number_feature(df, QY_xinxi_df):\n",
    "    temp_pivot_table = pd.pivot_table(QY_xinxi_df, index='qymc', values='clrq', aggfunc=len)\n",
    "    temp_pivot_table.reset_index(inplace=True)\n",
    "    temp_pivot_table.rename(columns={'clrq':'QYJL_number'}, inplace=True)\n",
    "    df = pd.merge(df, temp_pivot_table, on='qymc', how='left')\n",
    "    df['QYJL_number'] = df['QYJL_number'].fillna(0)\n",
    "    return df\n",
    "\n",
    "train_df = get_QYJL_number_feature(train_df, QY_xinxi_train_df)\n",
    "test_df = get_QYJL_number_feature(test_df, QY_xinxi_test_df)\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "#给训练集和测试集处理分支机构信息\n",
    "chusai_FZJGXX_train_df = pd.read_csv('../../chusai/data/train/分支机构信息.csv')\n",
    "fusai_FZJGXX_train_df = pd.read_csv('../data/train/分支机构信息.csv')\n",
    "FZJGXX_train_df = pd.concat([chusai_FZJGXX_train_df, fusai_FZJGXX_train_df])\n",
    "FZJGXX_train_df.fillna(-1, inplace=True)\n",
    "FZJGXX_train_df.rename(columns={'企业名称':'qymc', '分支机构省份':'fzjgsf', '分支企业名称':'fzqymc', '分支机构状态':'fzjgzt', \n",
    "                               '分支成立时间':'fzclsj', '分支死亡时间':'fzswsj', '分支行业门类':'fzhyml', '分支行业代码':'fzhydm', \n",
    "                               '分支机构区县':'fzjgqx', '分支机构类型':'fzjglx'}, inplace=True)\n",
    "FZJGXX_train_df.drop_duplicates(['qymc'], keep='first', inplace=True)\n",
    "train_df = pd.merge(train_df, FZJGXX_train_df, on='qymc', how='left')\n",
    "\n",
    "chusai_FZJGXX_test_df = pd.read_csv('../../chusai/data/test/分支机构信息.csv')\n",
    "fusai_FZJGXX_test_df = pd.read_csv('../data/test/分支机构信息.csv')\n",
    "FZJGXX_test_df = pd.concat([chusai_FZJGXX_test_df, fusai_FZJGXX_test_df])\n",
    "FZJGXX_test_df.fillna(-1, inplace=True)\n",
    "FZJGXX_test_df.rename(columns={'企业名称':'qymc', '分支机构省份':'fzjgsf', '分支企业名称':'fzqymc', '分支机构状态':'fzjgzt', \n",
    "                               '分支成立时间':'fzclsj', '分支死亡时间':'fzswsj', '分支行业门类':'fzhyml', '分支行业代码':'fzhydm', \n",
    "                               '分支机构区县':'fzjgqx', '分支机构类型':'fzjglx'}, inplace=True)\n",
    "FZJGXX_test_df.drop_duplicates(['qymc'], keep='first', inplace=True)\n",
    "test_df = pd.merge(test_df, FZJGXX_test_df, on='qymc', how='left')\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#统计跟分支成立死亡相关的特征\n",
    "def get_FZ_clsw_feature(df):\n",
    "    df['fzclsj'] = df['fzclsj'].map(lambda x : np.nan if ((x is np.nan) | (x == -1)) else datetime(int(x.split('/')[0]), int(x.split('/')[1]), int(x.split('/')[2])))\n",
    "    df['fzswsj'] = df['fzswsj'].map(lambda x : np.nan if ((x is np.nan) | (x == -1)) else datetime(int(x.split('/')[0]), int(x.split('/')[1]), int(x.split('/')[2])))\n",
    "    df['is_FZ_die'] = df['fzswsj'].map(lambda x : 1 if ((x != np.nan) & (x != -1)) else 0)\n",
    "    f = functools.partial(get_deltaDay, col1='fzclsj', col2='fzswsj')\n",
    "    df['fzsw_deltaDay'] = df.apply(f, axis=1)\n",
    "    return df\n",
    "\n",
    "train_df = get_FZ_clsw_feature(train_df)\n",
    "test_df = get_FZ_clsw_feature(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#处理跟机构设立登记信息相关\n",
    "chusai_JGSLDJXX_train_df = pd.read_csv('../../chusai/data/train/机构设立（变更）登记信息.csv')\n",
    "fusai_JGSLDJXX_train_df = pd.read_csv('../data/train/机构设立（变更）登记信息.csv')\n",
    "JGSLDJXX_train_df = pd.concat([chusai_JGSLDJXX_train_df, fusai_JGSLDJXX_train_df])\n",
    "JGSLDJXX_drop_list = ['机构全称英文', '备注', '设立登记类型', '法定代表人证件名称', '经济类型', '联系电话', '监管单位', '股东(发起人)', \n",
    "            '资金币种', '交换单位全称', '统一社会信用代码']\n",
    "JGSLDJXX_train_df.drop(JGSLDJXX_drop_list, axis=1, inplace=True)\n",
    "JGSLDJXX_train_df.fillna(-1, inplace=True)\n",
    "JGSLDJXX_train_df.rename(columns={'企业类型代码':'qylxdm', '企业类型名称':'qylxmc', '企业名称':'qymc', '数据状态':'sjzt', '数据来源':'sjly', '创建时间':'cjsj', '创建人ID':'cjrID',\n",
    "                                  '信息提供部门编码':'xxtgbmbm', '信息提供部门名称':'xxtgbmmc', '提供日期':'tgrq', '任务编号':'rwbh',\n",
    "                                 '组织机构代码':'zzjgdm', '工商注册号':'gszch', '种类':'zl', '法定代表人姓名':'fddbrxm', \n",
    "                                  '法定代表人证件号码':'fddbrzjhm', '注册（开办）资金':'zckbzj', '实收资金':'sszj', '经营范围':'jyfw',\n",
    "                                  '所属行业名称':'sshymc', '所属行业代码':'sshydm', '机构地址（住所）':'jgdzzs', '发证机关名称':'fzjgmc',\n",
    "                                 '发证日期':'fzrq', '（变更）核准日期':'bghzrq', '行政区划':'xzgh', '企业经度':'qyjd', '企业纬度':'qywd', \n",
    "                                 '是否有经纬度':'sfyjwd', '企业地址是否有变化':'qydzsfybh'}, inplace=True)\n",
    "JGSLDJXX_train_df.drop_duplicates(['qymc'], keep='first', inplace=True)\n",
    "train_df = pd.merge(train_df, JGSLDJXX_train_df, on='qymc', how='left')\n",
    "\n",
    "JGSLDJXX_test_df = pd.read_csv('../data/test/机构设立（变更）登记信息.csv')\n",
    "JGSLDJXX_test_df.drop(JGSLDJXX_drop_list, axis=1, inplace=True)\n",
    "JGSLDJXX_test_df.fillna(-1, inplace=True)\n",
    "JGSLDJXX_test_df.rename(columns={'企业类型代码':'qylxdm', '企业类型名称':'qylxmc', '企业名称':'qymc', '数据状态':'sjzt', '数据来源':'sjly', '创建时间':'cjsj', '创建人ID':'cjrID',\n",
    "                                  '信息提供部门编码':'xxtgbmbm', '信息提供部门名称':'xxtgbmmc', '提供日期':'tgrq', '任务编号':'rwbh',\n",
    "                                 '组织机构代码':'zzjgdm', '工商注册号':'gszch', '种类':'zl', '法定代表人姓名':'fddbrxm', \n",
    "                                  '法定代表人证件号码':'fddbrzjhm', '注册（开办）资金':'zckbzj', '实收资金':'sszj', '经营范围':'jyfw',\n",
    "                                  '所属行业名称':'sshymc', '所属行业代码':'sshydm', '机构地址（住所）':'jgdzzs', '发证机关名称':'fzjgmc',\n",
    "                                 '发证日期':'fzrq', '（变更）核准日期':'bghzrq', '行政区划':'xzgh', '企业经度':'qyjd', '企业纬度':'qywd', \n",
    "                                 '是否有经纬度':'sfyjwd', '企业地址是否有变化':'qydzsfybh'}, inplace=True)\n",
    "JGSLDJXX_test_df.drop_duplicates(['qymc'], keep='first', inplace=True)\n",
    "test_df = pd.merge(test_df, JGSLDJXX_test_df, on='qymc', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../temp/jyfw_w2v_online.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-47f1d8554445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../temp/jyfw_w2v_online.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mword_wv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \"\"\"\n\u001b[1;32m   1275\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m             \u001b[0;31m# for backward compatibility for `max_final_vocab` feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \"\"\"\n\u001b[0;32m-> 1101\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseWordEmbeddingsModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ns_exponent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mns_exponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \"\"\"\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseAny2VecModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m     \"\"\"\n\u001b[0;32m-> 1355\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1356\u001b[0m         \u001b[0;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mode should be a string'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shortcut_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../temp/jyfw_w2v_online.model'"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "my_model = Word2Vec.load('../temp/jyfw_w2v_online.model')\n",
    "word_wv = my_model.wv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "#定义jieba分词函数\n",
    "def jieba_sentences(sentence):\n",
    "    seg_list = jieba.cut(sentence)\n",
    "    seg_list = list(seg_list)\n",
    "    return seg_list\n",
    "\n",
    "def get_dir_w2v_array(word_list, word_wv, num_features):\n",
    "    word_vectors = np.zeros((len(word_list), num_features))\n",
    "    for i in range(len(word_list)):\n",
    "        if str(word_list[i]) in word_wv.vocab.keys():\n",
    "            word_vectors[i][:] = word_wv[str(word_list[i])]\n",
    "    mean_array = np.mean(word_vectors, axis=0)\n",
    "    return mean_array\n",
    "\n",
    "train_df['jyfw_jieba'] = train_df['jyfw'].map(lambda x : np.nan if x is np.nan else jieba_sentences(str(x)))\n",
    "test_df['jyfw_jieba'] = test_df['jyfw'].map(lambda x : np.nan if x is np.nan else jieba_sentences(str(x)))\n",
    "\n",
    "dir_num_features = 10\n",
    "train_df['jyfw_array'] = train_df['jyfw_jieba'].map(lambda x : np.zeros(dir_num_features) if x is np.nan else get_dir_w2v_array(x, word_wv, dir_num_features))\n",
    "test_df['jyfw_array'] = test_df['jyfw_jieba'].map(lambda x : np.zeros(dir_num_features) if x is np.nan else get_dir_w2v_array(x, word_wv, dir_num_features))\n",
    "\n",
    "def get_jyfw_w2v_feature(df, dir_num_features):\n",
    "    for i in range(dir_num_features):\n",
    "        df['jyfw_array_' + str(i) + '_fea'] = df['jyfw_array'].map(lambda x: np.nan if len(x) < (i+1) else x[i])\n",
    "    return df\n",
    "\n",
    "train_df = get_jyfw_w2v_feature(train_df, dir_num_features)\n",
    "test_df = get_jyfw_w2v_feature(test_df, dir_num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "chusai_FRXZXKZX_train_df = pd.read_csv('../../chusai/data/train/法人行政许可注（撤、吊）销信息.csv')\n",
    "fusai_FRXZXKZX_train_df = pd.read_csv('../data/train/法人行政许可注（撤、吊）销信息.csv')\n",
    "FRXZXKZX_train_df = pd.concat([chusai_FRXZXKZX_train_df, fusai_FRXZXKZX_train_df])\n",
    "FRXZXKZX_test_df = pd.read_csv('../data/test/法人行政许可注（撤、吊）销信息.csv')\n",
    "# print(len(FRXZXKZX_train_df))\n",
    "# print(FRXZXKZX_train_df.info())\n",
    "# print(FRXZXKZX_train_df.nunique())\n",
    "\n",
    "#初步统计法人行政许可注销信息\n",
    "def get_FRXZXKZX_number_feature(df, FRXZXKZX_df):\n",
    "    temp_pivot_table = pd.pivot_table(FRXZXKZX_df, index='企业名称', values='提供日期', aggfunc=len)\n",
    "    temp_pivot_table.reset_index(inplace=True)\n",
    "    temp_pivot_table.rename(columns={'提供日期':'FRXZXKZX_number', '企业名称':'qymc'}, inplace=True)\n",
    "    df = pd.merge(df, temp_pivot_table, on='qymc', how='left')\n",
    "    df['FRXZXKZX_number'] = df['FRXZXKZX_number'].fillna(0)\n",
    "    return df\n",
    "\n",
    "train_df = get_FRXZXKZX_number_feature(train_df, FRXZXKZX_train_df)\n",
    "test_df = get_FRXZXKZX_number_feature(test_df, FRXZXKZX_test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689\n"
     ]
    }
   ],
   "source": [
    "print(len(FRXZXKZX_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "chusai_QYBZRYXX_train_df = pd.read_csv('../../chusai/data/train/企业表彰荣誉信息.csv')\n",
    "fusai_QYBZRYXX_train_df = pd.read_csv('../data/train/企业表彰荣誉信息.csv')\n",
    "QYBZRYXX_train_df = pd.concat([chusai_QYBZRYXX_train_df, fusai_QYBZRYXX_train_df])\n",
    "QYBZRYXX_test_df = pd.read_csv('../data/test/企业表彰荣誉信息.csv')\n",
    "\n",
    "#初步统计企业表彰荣誉信息\n",
    "def get_QYBZRYXX_number_feature(df, QYBZRYXX_df):\n",
    "    temp_pivot_table = pd.pivot_table(QYBZRYXX_df, index='企业名称', values='创建时间', aggfunc=len)\n",
    "    temp_pivot_table.reset_index(inplace=True)\n",
    "    temp_pivot_table.rename(columns={'创建时间':'QYBZRYXX_number', '企业名称':'qymc'}, inplace=True)\n",
    "    df = pd.merge(df, temp_pivot_table, on='qymc', how='left')\n",
    "    df['QYBZRYXX_number'] = df['QYBZRYXX_number'].fillna(0)\n",
    "    return df\n",
    "\n",
    "train_df = get_QYBZRYXX_number_feature(train_df, QYBZRYXX_train_df)\n",
    "test_df = get_QYBZRYXX_number_feature(test_df, QYBZRYXX_test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061\n"
     ]
    }
   ],
   "source": [
    "print(len(set(QYBZRYXX_train_df['企业名称'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "chusai_QYFZCHRD_train_df = pd.read_csv('../../chusai/data/train/企业非正常户认定.csv')\n",
    "fusai_QYFZCHRD_train_df = pd.read_csv('../data/train/企业非正常户认定.csv')\n",
    "QYFZCHRD_train_df = pd.concat([chusai_QYFZCHRD_train_df, fusai_QYFZCHRD_train_df])\n",
    "QYFZCHRD_test_df = pd.read_csv('../data/test/企业非正常户认定.csv')\n",
    "QYFZCHRD_drop_list = ['创建人ID', '机构全称英文', '机构全称中文', '工商注册号', '统一社会信用代码', '备注', '数据状态']\n",
    "QYFZCHRD_train_df.drop(QYFZCHRD_drop_list, axis=1, inplace=True)\n",
    "QYFZCHRD_test_df.drop(QYFZCHRD_drop_list, axis=1, inplace=True)\n",
    "QYFZCHRD_train_df.rename(columns={'企业名称':'qymc', '关联机构设立登记表主键ID':'gljgsldjbzjID', '数据来源':'sjly', \n",
    "                                 '创建时间':'cjsj', '信息提供部门编码':'xxtgbmbm', '信息提供部门名称':'xxtgbmmc', \n",
    "                                 '提供日期':'tgrq', '任务编号':'rwbh', '组织机构代码':'zzjgdm', '税务管理码':'swglm', \n",
    "                                 '纳税人识别号':'nsrsbh', '纳税人状态':'nsrzt', '法定代表人姓名':'fddbrxm', \n",
    "                                 '登记注册类型':'djzclx', '注册地址':'zcdz', '认定日期':'rdrq', '应用年限':'yynx', \n",
    "                                 '管理机构':'gljg'}, inplace=True)\n",
    "QYFZCHRD_test_df.rename(columns={'企业名称':'qymc', '关联机构设立登记表主键ID':'gljgsldjbzjID', '数据来源':'sjly', \n",
    "                                 '创建时间':'cjsj', '信息提供部门编码':'xxtgbmbm', '信息提供部门名称':'xxtgbmmc', \n",
    "                                 '提供日期':'tgrq', '任务编号':'rwbh', '组织机构代码':'zzjgdm', '税务管理码':'swglm', \n",
    "                                 '纳税人识别号':'nsrsbh', '纳税人状态':'nsrzt', '法定代表人姓名':'fddbrxm', \n",
    "                                 '登记注册类型':'djzclx', '注册地址':'zcdz', '认定日期':'rdrq', '应用年限':'yynx', \n",
    "                                 '管理机构':'gljg'}, inplace=True)\n",
    "\n",
    "#初步统计企业非正常户认定\n",
    "def get_QYFZCHRD_number_feature(df, QYFZCHRD_df):\n",
    "    temp_pivot_table = pd.pivot_table(QYFZCHRD_df, index='qymc', values='cjsj', aggfunc=len)\n",
    "    temp_pivot_table.reset_index(inplace=True)\n",
    "    temp_pivot_table.rename(columns={'cjsj':'QYFZCHRD_number'}, inplace=True)\n",
    "    df = pd.merge(df, temp_pivot_table, on='qymc', how='left')\n",
    "    df['QYFZCHRD_number'] = df['QYFZCHRD_number'].fillna(0)\n",
    "    return df\n",
    "\n",
    "train_df = get_QYFZCHRD_number_feature(train_df, QYFZCHRD_train_df)\n",
    "test_df = get_QYFZCHRD_number_feature(test_df, QYFZCHRD_test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "#将企业非正常用户的一些字段merge到训练集中\n",
    "def get_QYFZCHRD_basic_feature(df, QYFZCHRD_df):\n",
    "    QYFZCHRD_df_copy = QYFZCHRD_df.copy()\n",
    "    QYFZCHRD_df_copy.drop_duplicates('qymc', inplace=True)\n",
    "    QYFZCHRD_df_copy.rename(columns={'rwbh':'QYFZCHRD_rwbh', 'zcdz':'QYFZCHRD_zcdz', 'xxtgbmmc':'QYFZCHRD_xxtgbmmc', 'swglm':'QYFZCHRD_swglm', 'gljg':'QYFZCHRD_gljg', 'djzclx':'QYFZCHRD_djzclx', 'yynx':'QYFZCHRD_yynx'}, inplace=True)\n",
    "    df = pd.merge(df, QYFZCHRD_df_copy[['qymc', 'QYFZCHRD_rwbh', 'QYFZCHRD_zcdz', 'QYFZCHRD_xxtgbmmc', 'QYFZCHRD_swglm', 'QYFZCHRD_gljg', 'QYFZCHRD_djzclx', 'QYFZCHRD_yynx']], on='qymc', how='left')\n",
    "    return df\n",
    "\n",
    "train_df = get_QYFZCHRD_basic_feature(train_df, QYFZCHRD_train_df)\n",
    "test_df = get_QYFZCHRD_basic_feature(test_df, QYFZCHRD_test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "chusai_QYSWDJXX_train_df = pd.read_csv('../../chusai/data/train/企业税务登记信息.csv')\n",
    "fusai_QYSWDJXX_train_df = pd.read_csv('../data/train/企业税务登记信息.csv')\n",
    "QYSWDJXX_train_df = pd.concat([chusai_QYSWDJXX_train_df, fusai_QYSWDJXX_train_df])\n",
    "QYSWDJXX_test_df = pd.read_csv('../data/test/企业税务登记信息.csv')\n",
    "QYSWDJXX_drop_list = ['任务编号', '变更日期', '数据状态', '创建人ID', '机构全称英文', '备注', '统一社会信用代码', '信息提供部门编码', '信息提供部门名称', '工商注册号']\n",
    "QYSWDJXX_train_df.drop(QYSWDJXX_drop_list, axis=1, inplace=True)\n",
    "QYSWDJXX_test_df.drop(QYSWDJXX_drop_list, axis=1, inplace=True)\n",
    "QYSWDJXX_train_df.rename(columns={'企业名称':'qymc', '关联机构设立登记表主键ID':'gljgsldjbzjID', '数据来源':'sjly', '创建时间':'cjsj', \n",
    "                                 '提供日期':'tgrq', '组织机构代码':'zzjgdm', '税务管理码':'swglm', '纳税人识别号':'nsrsbh', '法定代表人姓名':'fddbrxm', \n",
    "                                 '法定代表人证件名称':'fddbrzjmc', '登记注册类型':'djzclx', '审核结果':'shjg', '审核时间':'shsj',\n",
    "                                 '审核单位':'shdw', '区域':'qy'}, inplace=True)\n",
    "QYSWDJXX_test_df.rename(columns={'企业名称':'qymc', '关联机构设立登记表主键ID':'gljgsldjbzjID', '数据来源':'sjly', '创建时间':'cjsj', \n",
    "                                 '提供日期':'tgrq', '组织机构代码':'zzjgdm', '税务管理码':'swglm', '纳税人识别号':'nsrsbh', '法定代表人姓名':'fddbrxm', \n",
    "                                 '法定代表人证件名称':'fddbrzjmc', '登记注册类型':'djzclx', '审核结果':'shjg', '审核时间':'shsj',\n",
    "                                 '审核单位':'shdw', '区域':'qy'}, inplace=True)\n",
    "\n",
    "#初步统计企业税务登记信息\n",
    "def get_QYSWDJXX_number_feature(df, QYSWDJXX_df):\n",
    "    temp_pivot_table = pd.pivot_table(QYSWDJXX_df, index='qymc', values='cjsj', aggfunc=len)\n",
    "    temp_pivot_table.reset_index(inplace=True)\n",
    "    temp_pivot_table.rename(columns={'cjsj':'QYSWDJXX_number'}, inplace=True)\n",
    "    df = pd.merge(df, temp_pivot_table, on='qymc', how='left')\n",
    "    df['QYSWDJXX_number'] = df['QYSWDJXX_number'].fillna(0)\n",
    "    QYSWDJXX_df_copy = QYSWDJXX_df.copy()\n",
    "    QYSWDJXX_df_copy.drop_duplicates('qymc', inplace=True)\n",
    "    QYSWDJXX_df_copy.rename(columns={'fddbrzjmc':'QYSWDJXX_fddbrzjmc', 'shdw':'QYSWDJXX_shdw', 'qy':'QYSWDJXX_qy', 'shjg':'QYSWDJXX_shjg', 'djzclx':'QYSWDJXX_djzclx'}, inplace=True)\n",
    "    df = pd.merge(df, QYSWDJXX_df_copy[['qymc', 'QYSWDJXX_fddbrzjmc', 'QYSWDJXX_shdw', 'QYSWDJXX_qy', 'QYSWDJXX_shjg', 'QYSWDJXX_djzclx']], on='qymc', how='left')\n",
    "    return df\n",
    "\n",
    "train_df = get_QYSWDJXX_number_feature(train_df, QYSWDJXX_train_df)\n",
    "test_df = get_QYSWDJXX_number_feature(test_df, QYSWDJXX_test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "chusai_SDBDJQQJMCF_train_df = pd.read_csv('../../chusai/data/train/双打办打击侵权假冒处罚案件信息.csv')\n",
    "fusai_SDBDJQQJMCF_train_df = pd.read_csv('../data/train/双打办打击侵权假冒处罚案件信息.csv')\n",
    "SDBDJQQJMCF_train_df = pd.concat([chusai_SDBDJQQJMCF_train_df, fusai_SDBDJQQJMCF_train_df])\n",
    "SDBDJQQJMCF_test_df = pd.read_csv('../data/test/双打办打击侵权假冒处罚案件信息.csv')\n",
    "SDBDJQQJMCF_drop_list = ['数据状态', '数据来源', '创建人ID', '信息提供部门编码', '信息提供部门名称', '任务编号', '关联机构设立登记表主键ID', '被处罚的自然人姓名', '被处罚的自然人身份证号']\n",
    "SDBDJQQJMCF_train_df.drop(SDBDJQQJMCF_drop_list, axis=1, inplace=True)\n",
    "SDBDJQQJMCF_test_df.drop(SDBDJQQJMCF_drop_list, axis=1, inplace=True)\n",
    "SDBDJQQJMCF_train_df.rename(columns={'企业名称':'qymc', '创建时间':'cjsj', '提供日期':'tgrq', '行政处罚决定书文号':'xzcfjdswh', \n",
    "                                    '被处罚企业统一社会信用编码':'bcfqytyshxybm', '被处罚企业工商注册号':'bcfqygszch', '被处罚的企业法定代表人姓名':'bcfdqyfddbrxm', \n",
    "                                    '被处罚的企业法定代表人身份证号':'bcfdqyfddbrsfzh', '违反法律、法规或规章的主要事实':'wfflfghgzdzyss', \n",
    "                                    '行政处罚的种类和依据':'xzcfdzlhyj', '行政处罚的履行方式和期限':'xzcfdlxfshqx', '作出处罚决定的行政执法机关名称':'zccfjddxzzfjgmc', \n",
    "                                    '作出处罚决定的日期':'zccfjddrq', '公布方式及网址':'gbfsjwz'}, inplace=True)\n",
    "SDBDJQQJMCF_test_df.rename(columns={'企业名称':'qymc', '创建时间':'cjsj', '提供日期':'tgrq', '行政处罚决定书文号':'xzcfjdswh', \n",
    "                                    '被处罚企业统一社会信用编码':'bcfqytyshxybm', '被处罚企业工商注册号':'bcfqygszch', '被处罚的企业法定代表人姓名':'bcfdqyfddbrxm', \n",
    "                                    '被处罚的企业法定代表人身份证号':'bcfdqyfddbrsfzh', '违反法律、法规或规章的主要事实':'wfflfghgzdzyss', \n",
    "                                    '行政处罚的种类和依据':'xzcfdzlhyj', '行政处罚的履行方式和期限':'xzcfdlxfshqx', '作出处罚决定的行政执法机关名称':'zccfjddxzzfjgmc', \n",
    "                                    '作出处罚决定的日期':'zccfjddrq', '公布方式及网址':'gbfsjwz'}, inplace=True)\n",
    "\n",
    "#初步统计双打办打击侵权假冒处罚案件信息\n",
    "def get_SDBDJQQJMCF_number_feature(df, SDBDJQQJMCF_df):\n",
    "    temp_pivot_table = pd.pivot_table(SDBDJQQJMCF_df, index='qymc', values='cjsj', aggfunc=len)\n",
    "    temp_pivot_table.reset_index(inplace=True)\n",
    "    temp_pivot_table.rename(columns={'cjsj':'SDBDJQQJMCF_number'}, inplace=True)\n",
    "    df = pd.merge(df, temp_pivot_table, on='qymc', how='left')\n",
    "    df['SDBDJQQJMCF_number'] = df['SDBDJQQJMCF_number'].fillna(0)\n",
    "    return df\n",
    "\n",
    "train_df = get_SDBDJQQJMCF_number_feature(train_df, SDBDJQQJMCF_train_df)\n",
    "test_df = get_SDBDJQQJMCF_number_feature(test_df, SDBDJQQJMCF_test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416\n",
      "56731\n"
     ]
    }
   ],
   "source": [
    "print(len(set(SDBDJQQJMCF_train_df['qymc'])))\n",
    "print(len(train_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "chusai_SGSFRXZXKXX_train_df = pd.read_csv('../../chusai/data/train/双公示-法人行政许可信息.csv')\n",
    "fusai_SGSFRXZXKXX_train_df = pd.read_csv('../data/train/双公示-法人行政许可信息.csv')\n",
    "SGSFRXZXKXX_train_df = pd.concat([chusai_SGSFRXZXKXX_train_df, fusai_SGSFRXZXKXX_train_df])\n",
    "SGSFRXZXKXX_test_df = pd.read_csv('../data/test/双公示-法人行政许可信息.csv')\n",
    "SGSFRXZXKXX_drop_list = ['自动上报信用中国状态', '自动上报时间', '错误原因', '接口返回信用中国的ID', '任务编号', '机构全称英文', '备注', '行政相对人税务登记号']\n",
    "SGSFRXZXKXX_train_df.drop(SGSFRXZXKXX_drop_list, axis=1, inplace=True)\n",
    "SGSFRXZXKXX_test_df.drop(SGSFRXZXKXX_drop_list, axis=1, inplace=True)\n",
    "# print(SGSFRXZXKXX_train_df.nunique())\n",
    "SGSFRXZXKXX_train_df.rename(columns={'企业名称':'qymc', '关联机构设立登记表主键ID':'gljgsldjbzjID', '进入业务库的时间':'jrywkdsj', \n",
    "                                    '数据状态_1':'sjzt1', '数据来源':'sjly', '创建时间':'cjsj', '创建人ID':'cjrID', '信息提供部门编码':'xxtgbmbm', \n",
    "                                    '信息提供部门名称':'xxtgbmmc', '提供日期':'tgrq', '行政相对人代码_2':'xzxdrdm2', '行政相对人代码＿3':'xzxdrdm3', \n",
    "                                    '行政相对人代码_1':'xzxdrdm1', '许可决定书文号':'xkjdswh', '项目名称':'xmmc', '行政许可编码':'xzxkbm', '审批类别':'splb', \n",
    "                                     '许可内容':'xknr', '行政相对人名称':'xzxdrmc', '行政相对人代码＿4':'xzxdrdm4', '法定代表人名称':'fddbrmc', \n",
    "                                     '行政相对人代码＿5':'xzxdrdm5', '许可决定日期':'xkjdrq', '许可截止期':'xkjzq', '许可机关':'xkjg', '数据状态_2':'sjzt2', \n",
    "                                    '地方编码':'dfbm', '数据更新时间戳':'sjgxsjc', '信息使用范围':'xysyfw', '公示截止期':'gsjzq'}, inplace=True)\n",
    "SGSFRXZXKXX_test_df.rename(columns={'企业名称':'qymc', '关联机构设立登记表主键ID':'gljgsldjbzjID', '进入业务库的时间':'jrywkdsj', \n",
    "                                    '数据状态_1':'sjzt1', '数据来源':'sjly', '创建时间':'cjsj', '创建人ID':'cjrID', '信息提供部门编码':'xxtgbmbm', \n",
    "                                    '信息提供部门名称':'xxtgbmmc', '提供日期':'tgrq', '行政相对人代码_2':'xzxdrdm2', '行政相对人代码＿3':'xzxdrdm3', \n",
    "                                    '行政相对人代码_1':'xzxdrdm1', '许可决定书文号':'xkjdswh', '项目名称':'xmmc', '行政许可编码':'xzxkbm', '审批类别':'splb', \n",
    "                                     '许可内容':'xknr', '行政相对人名称':'xzxdrmc', '行政相对人代码＿4':'xzxdrdm4', '法定代表人名称':'fddbrmc', \n",
    "                                     '行政相对人代码＿5':'xzxdrdm5', '许可决定日期':'xkjdrq', '许可截止期':'xkjzq', '许可机关':'xkjg', '数据状态_2':'sjzt2', \n",
    "                                    '地方编码':'dfbm', '数据更新时间戳':'sjgxsjc', '信息使用范围':'xysyfw', '公示截止期':'gsjzq'}, inplace=True)\n",
    "# print(SGSFRXZXKXX_train_df.info())\n",
    "# print(SGSFRXZXKXX_train_df.head())\n",
    "\n",
    "#初步统计双公示-法人行政许可信息\n",
    "def get_SGSFRXZXKXX_number_feature(df, SGSFRXZXKXX_df):\n",
    "    temp_pivot_table = pd.pivot_table(SGSFRXZXKXX_df, index='qymc', values='cjsj', aggfunc=len)\n",
    "    temp_pivot_table.reset_index(inplace=True)\n",
    "    temp_pivot_table.rename(columns={'cjsj':'SGSFRXZXKXX_number'}, inplace=True)\n",
    "    df = pd.merge(df, temp_pivot_table, on='qymc', how='left')\n",
    "    df['SGSFRXZXKXX_number'] = df['SGSFRXZXKXX_number'].fillna(0)\n",
    "    return df\n",
    "\n",
    "train_df = get_SGSFRXZXKXX_number_feature(train_df, SGSFRXZXKXX_train_df)\n",
    "test_df = get_SGSFRXZXKXX_number_feature(test_df, SGSFRXZXKXX_test_df)\n",
    "print(len(test_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "#开始统计跟法人行政许可相关的信息\n",
    "def get_FRXZXK_last_statistic_feature(df, SGSFRXZXKXX_df):\n",
    "    SGSFRXZXKXX_df_copy = SGSFRXZXKXX_df.copy()\n",
    "    SGSFRXZXKXX_df_copy.sort_values(by=['qymc', 'xkjzq'], ascending=False, inplace=True)\n",
    "    SGSFRXZXKXX_df_copy.drop_duplicates('qymc', keep='first', inplace=True)\n",
    "    SGSFRXZXKXX_df_copy.rename(columns={'xzxkbm':'SGSFRXZXKXX_xzxkbm', 'xkjdswh':'SGSFRXZXKXX_xkjdswh', 'xxtgbmmc':'SGSFRXZXKXX_xxtgbmmc', 'xknr':'SGSFRXZXKXX_xknr', 'xmmc':'SGSFRXZXKXX_xmmc', 'splb':'SGSFRXZXKXX_splb', 'dfbm':'SGSFRXZXKXX_dfbm', 'xkjg':'SGSFRXZXKXX_xkjg', 'xkjzq':'SGSFRXZXKXX_xkjzq', 'xysyfw':'SGSFRXZXKXX_xysyfw', 'sjzt2':'SGSFRXZXKXX_sjzt2', 'xkjdrq':'SGSFRXZXKXX_xkjdrq'}, inplace=True)\n",
    "    df = pd.merge(df, SGSFRXZXKXX_df_copy[['qymc', 'SGSFRXZXKXX_xzxkbm', 'SGSFRXZXKXX_xkjdswh', 'SGSFRXZXKXX_xxtgbmmc', 'SGSFRXZXKXX_xknr', 'SGSFRXZXKXX_xmmc', 'SGSFRXZXKXX_splb', 'SGSFRXZXKXX_dfbm', 'SGSFRXZXKXX_xkjg', 'SGSFRXZXKXX_xkjzq', 'SGSFRXZXKXX_xkjdrq', 'SGSFRXZXKXX_xysyfw', 'SGSFRXZXKXX_sjzt2']], on='qymc', how='left')\n",
    "    df['SGSFRXZXKXX_xkjzq'] = df['SGSFRXZXKXX_xkjzq'].map(lambda x : np.nan if x is np.nan else pd.to_datetime(x))\n",
    "    df['SGSFRXZXKXX_xkjdrq'] = df['SGSFRXZXKXX_xkjdrq'].map(lambda x : np.nan if x is np.nan else pd.to_datetime(x))\n",
    "    df['SGSFRXZXKXX_xkjzq_year'] = df['SGSFRXZXKXX_xkjzq'].map(lambda x : np.nan if x is np.nan else x.year)\n",
    "    df['SGSFRXZXKXX_xkjzq_month'] = df['SGSFRXZXKXX_xkjzq'].map(lambda x : np.nan if x is np.nan else x.month)\n",
    "    df['SGSFRXZXKXX_xkjzq_day'] = df['SGSFRXZXKXX_xkjzq'].map(lambda x : np.nan if x is np.nan else x.day)\n",
    "    df['SGSFRXZXKXX_xkjdrq_year'] = df['SGSFRXZXKXX_xkjdrq'].map(lambda x : np.nan if x is np.nan else x.year)\n",
    "    df['SGSFRXZXKXX_xkjdrq_month'] = df['SGSFRXZXKXX_xkjdrq'].map(lambda x : np.nan if x is np.nan else x.month)\n",
    "    df['SGSFRXZXKXX_xkjdrq_day'] = df['SGSFRXZXKXX_xkjdrq'].map(lambda x : np.nan if x is np.nan else x.day)\n",
    "    f1 = functools.partial(get_deltaDay, col1='SGSFRXZXKXX_xkjdrq', col2='SGSFRXZXKXX_xkjzq')\n",
    "    df['SGSFRXZXKXX_xkjdjz_deltaDay'] = df.apply(f1, axis=1)\n",
    "    f2 = functools.partial(get_deltaDay, col1='clrq', col2='SGSFRXZXKXX_xkjzq')\n",
    "    df['clxkjz_deltaDay'] = df.apply(f2, axis=1)\n",
    "    f3 = functools.partial(get_deltaDay, col1='hzrq', col2='SGSFRXZXKXX_xkjzq')\n",
    "    df['hzxkjz_deltaDay'] = df.apply(f3, axis=1)\n",
    "    f4 = functools.partial(get_deltaDay, col1='clrq', col2='SGSFRXZXKXX_xkjdrq')\n",
    "    df['clxkjd_deltaDay'] = df.apply(f4, axis=1)\n",
    "    f5 = functools.partial(get_deltaDay, col1='hzrq', col2='SGSFRXZXKXX_xkjdrq')\n",
    "    df['hzxkjd_deltaDay'] = df.apply(f5, axis=1)\n",
    "    return df\n",
    "    \n",
    "train_df = get_FRXZXK_last_statistic_feature(train_df, SGSFRXZXKXX_train_df)\n",
    "test_df = get_FRXZXK_last_statistic_feature(test_df, SGSFRXZXKXX_test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "chusai_XKZZNJXX_train_df = pd.read_csv('../../chusai/data/train/许可资质年检信息.csv')\n",
    "fusai_XKZZNJXX_train_df = pd.read_csv('../data/train/许可资质年检信息.csv')\n",
    "XKZZNJXX_train_df = pd.concat([chusai_XKZZNJXX_train_df, fusai_XKZZNJXX_train_df])\n",
    "XKZZNJXX_test_df = pd.read_csv('../data/test/许可资质年检信息.csv')\n",
    "XKZZNJXX_drop_list = ['数据状态', '数据来源', '创建人ID', '任务编号', '机构全称英文', '备注', '权力名称', '权力编码', '统一社会信用代码']\n",
    "XKZZNJXX_train_df.drop(XKZZNJXX_drop_list, axis=1, inplace=True)\n",
    "XKZZNJXX_test_df.drop(XKZZNJXX_drop_list, axis=1, inplace=True)\n",
    "# print(XKZZNJXX_train_df.nunique())\n",
    "XKZZNJXX_train_df.rename(columns={'企业名称':'qymc', '关联机构设立登记表主键ID':'gljgsldjbzjID', '创建时间':'cjsj', '信息提供部门编码':'xxtgbmbm', \n",
    "                                 '信息提供部门名称':'xxtgbmmc', '提供日期':'tgrq', '组织机构代码':'zzjgdm', '工商注册号':'gszch', '证书编号':'zsbh', \n",
    "                                 '年检年度':'njnd', '年检结果':'njjg', '年检机关全称':'njjgmc', '年检事项名称':'njsxmc', '年检日期':'njrq', '交换单位全称':'jhdwqc'}, inplace=True)\n",
    "XKZZNJXX_test_df.rename(columns={'企业名称':'qymc', '关联机构设立登记表主键ID':'gljgsldjbzjID', '创建时间':'cjsj', '信息提供部门编码':'xxtgbmbm', \n",
    "                                 '信息提供部门名称':'xxtgbmmc', '提供日期':'tgrq', '组织机构代码':'zzjgdm', '工商注册号':'gszch', '证书编号':'zsbh', \n",
    "                                 '年检年度':'njnd', '年检结果':'njjg', '年检机关全称':'njjgmc', '年检事项名称':'njsxmc', '年检日期':'njrq', '交换单位全称':'jhdwqc'}, inplace=True)\n",
    "# print(XKZZNJXX_train_df.info())\n",
    "# print(XKZZNJXX_train_df.head())\n",
    "\n",
    "#初步统计许可资质年检信息\n",
    "def get_XKZZNJXX_number_feature(df, XKZZNJXX_df):\n",
    "    temp_pivot_table = pd.pivot_table(XKZZNJXX_df, index='qymc', values='cjsj', aggfunc=len)\n",
    "    temp_pivot_table.reset_index(inplace=True)\n",
    "    temp_pivot_table.rename(columns={'cjsj':'XKZZNJXX_number'}, inplace=True)\n",
    "    df = pd.merge(df, temp_pivot_table, on='qymc', how='left')\n",
    "    df['XKZZNJXX_number'] = df['XKZZNJXX_number'].fillna(0)\n",
    "    return df\n",
    "\n",
    "train_df = get_XKZZNJXX_number_feature(train_df, XKZZNJXX_train_df)\n",
    "test_df = get_XKZZNJXX_number_feature(test_df, XKZZNJXX_test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "#开始统计跟许可资质年检信息\n",
    "def get_XKZZNJXX_last_statistic_feature(df, XKZZNJXX_df):\n",
    "    XKZZNJXX_df_copy = XKZZNJXX_df.copy()\n",
    "    XKZZNJXX_df_copy.sort_values(by=['qymc', 'njrq'], ascending=False, inplace=True)\n",
    "    XKZZNJXX_df_copy.drop_duplicates('qymc', keep='first', inplace=True)\n",
    "    XKZZNJXX_df_copy.rename(columns={'xxtgbmmc':'XKZZNJXX_xxtgbmmc', 'njrq':'XKZZNJXX_njrq', 'njnd':'XKZZNJXX_njnd', 'njjgmc':'XKZZNJXX_njjgmc', 'njsxmc':'XKZZNJXX_njsxmc'}, inplace=True)\n",
    "    df = pd.merge(df, XKZZNJXX_df_copy[['qymc', 'XKZZNJXX_xxtgbmmc', 'XKZZNJXX_njrq', 'XKZZNJXX_njnd', 'XKZZNJXX_njjgmc', 'XKZZNJXX_njsxmc']], on='qymc', how='left')\n",
    "    df['XKZZNJXX_njrq'] = df['XKZZNJXX_njrq'].map(lambda x : np.nan if x is np.nan else pd.to_datetime(x))\n",
    "    df['XKZZNJXX_njrq_year'] = df['XKZZNJXX_njrq'].map(lambda x : np.nan if x is np.nan else x.year)\n",
    "    df['XKZZNJXX_njrq_month'] = df['XKZZNJXX_njrq'].map(lambda x : np.nan if x is np.nan else x.month)\n",
    "    df['XKZZNJXX_njrq_day'] = df['XKZZNJXX_njrq'].map(lambda x : np.nan if x is np.nan else x.day)\n",
    "    f1 = functools.partial(get_deltaDay, col1='hzrq', col2='XKZZNJXX_njrq')\n",
    "    df['njhz_deltaDay'] = df.apply(f1, axis=1)\n",
    "    f2 = functools.partial(get_deltaDay, col1='clrq', col2='XKZZNJXX_njrq')\n",
    "    df['njcl_deltaDay'] = df.apply(f2, axis=1)\n",
    "    return df\n",
    "    \n",
    "train_df = get_XKZZNJXX_last_statistic_feature(train_df, XKZZNJXX_train_df)\n",
    "test_df = get_XKZZNJXX_last_statistic_feature(test_df, XKZZNJXX_test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "chusai_ZPSJ_train_df = pd.read_csv('../../chusai/data/train/招聘数据.csv')\n",
    "fusai_ZPSJ_train_df = pd.read_csv('../data/train/招聘数据.csv')\n",
    "ZPSJ_train_df = pd.concat([chusai_ZPSJ_train_df, fusai_ZPSJ_train_df])\n",
    "ZPSJ_test_df = pd.read_csv('../data/test/招聘数据.csv')\n",
    "# print(ZPSJ_train_df.nunique())\n",
    "# print(ZPSJ_train_df.info())\n",
    "ZPSJ_train_df.rename(columns={'企业名称':'qymc', '网站名称':'wzmc', '工作经验':'gzjy', '工作地点':'gzdd', '职位类别':'zylb',\n",
    "                             '招聘人数':'zprs', '职位月薪':'zwyx', '最低学历':'zdxl', '业务主键':'ywzj', '招聘日期':'zprq'}, inplace=True)\n",
    "ZPSJ_test_df.rename(columns={'企业名称':'qymc', '网站名称':'wzmc', '工作经验':'gzjy', '工作地点':'gzdd', '职位类别':'zylb',\n",
    "                             '招聘人数':'zprs', '职位月薪':'zwyx', '最低学历':'zdxl', '业务主键':'ywzj', '招聘日期':'zprq'}, inplace=True)\n",
    "# print(ZPSJ_train_df.head())\n",
    "\n",
    "#初步统计招聘数据\n",
    "def get_ZPSJ_number_feature(df, ZPSJ_df):\n",
    "    temp_pivot_table = pd.pivot_table(ZPSJ_df, index='qymc', values='zprq', aggfunc=len)\n",
    "    temp_pivot_table.reset_index(inplace=True)\n",
    "    temp_pivot_table.rename(columns={'zprq':'ZPSJ_number'}, inplace=True)\n",
    "    df = pd.merge(df, temp_pivot_table, on='qymc', how='left')\n",
    "    df['ZPSJ_number'] = df['ZPSJ_number'].fillna(0)\n",
    "    return df\n",
    "\n",
    "train_df = get_ZPSJ_number_feature(train_df, ZPSJ_train_df)\n",
    "test_df = get_ZPSJ_number_feature(test_df, ZPSJ_test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#开始统计跟招聘信息种类相关的特征\n",
    "def get_ZPSJ_kind_feature(df, ZPSJ_df):\n",
    "    fea_list = ['zylb', 'gzjy', 'gzdd', 'zprs', 'zwyx', 'zdxl', 'zprq']\n",
    "    for fea in fea_list:\n",
    "        temp_df_pivot_table = pd.pivot_table(ZPSJ_df, index=['qymc', fea], values='wzmc', aggfunc=len)\n",
    "        temp_df_pivot_table.reset_index(inplace=True)\n",
    "        temp = pd.pivot_table(temp_df_pivot_table, index='qymc', values=fea, aggfunc=len)\n",
    "        temp.reset_index(inplace=True)\n",
    "        temp.rename(columns={fea:'ZPSJ_' + fea + '_kinds'}, inplace=True)\n",
    "        df = pd.merge(df, temp, on='qymc', how='left')\n",
    "    return df\n",
    "\n",
    "train_df = get_ZPSJ_kind_feature(train_df, ZPSJ_train_df)\n",
    "test_df = get_ZPSJ_kind_feature(test_df, ZPSJ_test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#统计跟招聘人数相关的统计特征\n",
    "def get_ZPSJ_zprs_statistic_feature(df, ZPSJ_df):\n",
    "    mode = re.compile(r'\\d+')\n",
    "    ZPSJ_df['zprs'] = ZPSJ_df['zprs'].map(lambda x : np.nan if x is np.nan else (np.nan if len(mode.findall(str(x))) <= 0 else int(mode.findall(str(x))[0])))\n",
    "    temp = ZPSJ_df[ZPSJ_df.zprs.notnull()]\n",
    "    temp_pivot_table = pd.pivot_table(temp, index='qymc', values='zprs', aggfunc=[np.max, np.min, np.mean, np.std])\n",
    "    temp_pivot_table.reset_index(inplace=True)\n",
    "    temp_pivot_table.columns = ['qymc', 'ZPSJ_zprs_max', 'ZPSJ_zprs_min', 'ZPSJ_zprs_mean', 'ZPSJ_zprs_std']\n",
    "    df = pd.merge(df, temp_pivot_table, on='qymc', how='left')\n",
    "    return df\n",
    "    \n",
    "train_df = get_ZPSJ_zprs_statistic_feature(train_df, ZPSJ_train_df)\n",
    "test_df = get_ZPSJ_zprs_statistic_feature(test_df, ZPSJ_test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "chusai_ZZDJBGXX_train_df = pd.read_csv('../../chusai/data/train/资质登记（变更）信息.csv')\n",
    "fusai_ZZDJBGXX_train_df = pd.read_csv('../data/train/资质登记（变更）信息.csv')\n",
    "ZZDJBGXX_train_df = pd.concat([chusai_ZZDJBGXX_train_df, fusai_ZZDJBGXX_train_df])\n",
    "ZZDJBGXX_test_df = pd.read_csv('../data/test/资质登记（变更）信息.csv')\n",
    "ZZDJBGXX_drop_list = ['数据状态', '创建人ID', '数据来源', '创建人ID', '任务编号', '机构全称英文', '统一社会信用代码', \n",
    "                      '备注', '资质等级', '交换单位全称', '权力名称', '权力编码', '变更核准日期', '种类']\n",
    "ZZDJBGXX_train_df.drop(ZZDJBGXX_drop_list, axis=1, inplace=True)\n",
    "ZZDJBGXX_test_df.drop(ZZDJBGXX_drop_list, axis=1, inplace=True)\n",
    "# print(ZZDJBGXX_train_df.nunique())\n",
    "ZZDJBGXX_train_df.rename(columns={'企业名称':'qymc', '关联机构设立登记表主键ID':'gljgsldjbzjID', '创建时间':'cjsj', '信息提供部门编码':'xxtgbmbm', \n",
    "                                 '信息提供部门名称':'xxtgbmmc', '提供日期':'tgrq', '组织机构代码':'zzjgdm', '工商注册号':'gszch', '资质证书编号':'zzzsbh', \n",
    "                                 '资质名称':'zzmc', '执业范围':'zyfw', '资质生效期':'zzsxq', '资质截止期':'zzjzq', '认定机关全称':'rdjgqc', \n",
    "                                 '认定日期':'rdrq'}, inplace=True)\n",
    "ZZDJBGXX_test_df.rename(columns={'企业名称':'qymc', '关联机构设立登记表主键ID':'gljgsldjbzjID', '创建时间':'cjsj', '信息提供部门编码':'xxtgbmbm', \n",
    "                                 '信息提供部门名称':'xxtgbmmc', '提供日期':'tgrq', '组织机构代码':'zzjgdm', '工商注册号':'gszch', '资质证书编号':'zzzsbh', \n",
    "                                 '资质名称':'zzmc', '执业范围':'zyfw', '资质生效期':'zzsxq', '资质截止期':'zzjzq', '认定机关全称':'rdjgqc', \n",
    "                                 '认定日期':'rdrq'}, inplace=True)\n",
    "# print(ZZDJBGXX_train_df.info())\n",
    "# print(ZZDJBGXX_train_df.head())\n",
    "\n",
    "#初步统计资质登记（变更）信息\n",
    "def get_ZZDJBGXX_number_feature(df, ZZDJBGXX_df):\n",
    "    temp_pivot_table = pd.pivot_table(ZZDJBGXX_df, index='qymc', values='cjsj', aggfunc=len)\n",
    "    temp_pivot_table.reset_index(inplace=True)\n",
    "    temp_pivot_table.rename(columns={'cjsj':'ZZDJBGXX_number'}, inplace=True)\n",
    "    df = pd.merge(df, temp_pivot_table, on='qymc', how='left')\n",
    "    df['ZZDJBGXX_number'] = df['ZZDJBGXX_number'].fillna(0)\n",
    "    return df\n",
    "\n",
    "train_df = get_ZZDJBGXX_number_feature(train_df, ZZDJBGXX_train_df)\n",
    "test_df = get_ZZDJBGXX_number_feature(test_df, ZZDJBGXX_test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17534\n"
     ]
    }
   ],
   "source": [
    "#开始统计跟资质登记（变更）信息\n",
    "def get_ZZDJBGXX_last_statistic_feature(df, ZZDJBGXX_df):\n",
    "    ZZDJBGXX_df_copy = ZZDJBGXX_df.copy()\n",
    "    ZZDJBGXX_df_copy.sort_values(by=['qymc', 'zzjzq'], ascending=False, inplace=True)\n",
    "    ZZDJBGXX_df_copy.drop_duplicates('qymc', keep='first', inplace=True)\n",
    "    ZZDJBGXX_df_copy.rename(columns={'zzmc':'ZZDJBGXX_zzmc', 'zyfw':'ZZDJBGXX_zyfw', 'zzsxq':'ZZDJBGXX_zzsxq', 'zzjzq':'ZZDJBGXX_zzjzq', 'rdjgqc':'ZZDJBGXX_rdjgqc', 'zzzsbh':'ZZDJBGXX_zzzsbh'}, inplace=True)\n",
    "    df = pd.merge(df, ZZDJBGXX_df_copy[['qymc', 'ZZDJBGXX_zzmc', 'ZZDJBGXX_zyfw', 'ZZDJBGXX_zzsxq', 'ZZDJBGXX_zzjzq', 'ZZDJBGXX_rdjgqc', 'ZZDJBGXX_zzzsbh']], on='qymc', how='left')\n",
    "    df['ZZDJBGXX_zzsxq'] = df['ZZDJBGXX_zzsxq'].map(lambda x : np.nan if x is np.nan else pd.to_datetime(x))\n",
    "    df['ZZDJBGXX_zzsxq_year'] = df['ZZDJBGXX_zzsxq'].map(lambda x : np.nan if x is np.nan else x.year)\n",
    "    df['ZZDJBGXX_zzsxq_month'] = df['ZZDJBGXX_zzsxq'].map(lambda x : np.nan if x is np.nan else x.month)\n",
    "    df['ZZDJBGXX_zzsxq_day'] = df['ZZDJBGXX_zzsxq'].map(lambda x : np.nan if x is np.nan else x.day)\n",
    "    df['ZZDJBGXX_zzjzq'] = df['ZZDJBGXX_zzjzq'].map(lambda x : np.nan if x is np.nan else pd.to_datetime(x))\n",
    "    df['ZZDJBGXX_zzjzq_year'] = df['ZZDJBGXX_zzjzq'].map(lambda x : np.nan if x is np.nan else x.year)\n",
    "    df['ZZDJBGXX_zzjzq_month'] = df['ZZDJBGXX_zzjzq'].map(lambda x : np.nan if x is np.nan else x.month)\n",
    "    df['ZZDJBGXX_zzjzq_day'] = df['ZZDJBGXX_zzjzq'].map(lambda x : np.nan if x is np.nan else x.day)\n",
    "    f = functools.partial(get_deltaDay, col1='ZZDJBGXX_zzsxq', col2='ZZDJBGXX_zzjzq')\n",
    "    df['ZZDJBGXX_jzsx_deltaDay'] = df.apply(f, axis=1)\n",
    "    f1 = functools.partial(get_deltaDay, col1='clrq', col2='ZZDJBGXX_zzsxq')\n",
    "    df['zzsxcl_deltaDay'] = df.apply(f1, axis=1)\n",
    "    f2 = functools.partial(get_deltaDay, col1='clrq', col2='ZZDJBGXX_zzjzq')\n",
    "    df['zzjzcl_deltaDay'] = df.apply(f2, axis=1)\n",
    "    f3 = functools.partial(get_deltaDay, col1='hzrq', col2='ZZDJBGXX_zzsxq')\n",
    "    df['zzsxhz_deltaDay'] = df.apply(f3, axis=1)\n",
    "    f4 = functools.partial(get_deltaDay, col1='hzrq', col2='ZZDJBGXX_zzjzq')\n",
    "    df['zzjzhz_deltaDay'] = df.apply(f4, axis=1)\n",
    "    return df\n",
    "    \n",
    "train_df = get_ZZDJBGXX_last_statistic_feature(train_df, ZZDJBGXX_train_df)\n",
    "test_df = get_ZZDJBGXX_last_statistic_feature(test_df, ZZDJBGXX_test_df)\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['jgdzzs_top3'] = train_df['jgdzzs'].map(lambda x : np.nan if x is np.nan else x[:3] if len(x) >=3 else x)\n",
    "train_df['jgdzzs_top6'] = train_df['jgdzzs'].map(lambda x : np.nan if x is np.nan else x[:6] if len(x) >=6 else x)\n",
    "test_df['jgdzzs_top3'] = test_df['jgdzzs'].map(lambda x : np.nan if x is np.nan else x[:3] if len(x) >=3 else x)\n",
    "test_df['jgdzzs_top6'] = test_df['jgdzzs'].map(lambda x : np.nan if x is np.nan else x[:6] if len(x) >=6 else x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "float_columns_list = ['zczj', 'fzjgsf', 'fzjgzt', 'fzhydm', 'fzjgqx', 'fzjglx', 'sjly', 'rwbh', 'zckbzj', 'sshydm', 'xzgh', \n",
    "                      'qyjd', 'qywd', 'sfyjwd', 'qylxdm', 'QYFZCHRD_yynx', 'SGSFRXZXKXX_dfbm']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sshydm finish!!!\n",
      "tyshxydm finish!!!\n",
      "zczbbzmc finish!!!\n",
      "hymldm finish!!!\n",
      "zsszdsf finish!!!\n",
      "fzhyml finish!!!\n",
      "xxtgbmmc finish!!!\n",
      "zl finish!!!\n",
      "sszj finish!!!\n",
      "fzjgmc finish!!!\n",
      "qyjglxmc finish!!!\n",
      "qylxmc finish!!!\n",
      "QYFZCHRD_swglm finish!!!\n",
      "QYFZCHRD_gljg finish!!!\n",
      "QYFZCHRD_djzclx finish!!!\n",
      "SGSFRXZXKXX_xknr finish!!!\n",
      "SGSFRXZXKXX_xmmc finish!!!\n",
      "SGSFRXZXKXX_splb finish!!!\n",
      "SGSFRXZXKXX_xkjg finish!!!\n",
      "SGSFRXZXKXX_xysyfw finish!!!\n",
      "SGSFRXZXKXX_sjzt2 finish!!!\n",
      "XKZZNJXX_njnd finish!!!\n",
      "XKZZNJXX_njjgmc finish!!!\n",
      "XKZZNJXX_njsxmc finish!!!\n",
      "ZZDJBGXX_zzmc finish!!!\n",
      "ZZDJBGXX_zyfw finish!!!\n",
      "ZZDJBGXX_rdjgqc finish!!!\n",
      "ZZDJBGXX_zzzsbh finish!!!\n",
      "jgdzzs finish!!!\n",
      "jyfw finish!!!\n",
      "sshymc finish!!!\n",
      "fzrq finish!!!\n",
      "bghzrq finish!!!\n",
      "gszch finish!!!\n",
      "fddbrzjhm finish!!!\n",
      "zzjgdm finish!!!\n",
      "SGSFRXZXKXX_xzxkbm finish!!!\n",
      "SGSFRXZXKXX_xkjdswh finish!!!\n",
      "SGSFRXZXKXX_xxtgbmmc finish!!!\n",
      "XKZZNJXX_xxtgbmmc finish!!!\n",
      "QYFZCHRD_rwbh finish!!!\n",
      "QYFZCHRD_zcdz finish!!!\n",
      "QYFZCHRD_xxtgbmmc finish!!!\n",
      "jgdzzs_top3 finish!!!\n",
      "jgdzzs_top6 finish!!!\n",
      "QYSWDJXX_fddbrzjmc finish!!!\n",
      "QYSWDJXX_shdw finish!!!\n",
      "QYSWDJXX_qy finish!!!\n",
      "QYSWDJXX_shjg finish!!!\n",
      "QYSWDJXX_djzclx finish!!!\n"
     ]
    }
   ],
   "source": [
    "temp_df = pd.concat([train_df, test_df])\n",
    "\n",
    "# labelencoder 转化\n",
    "# labelencoder 转化\n",
    "labelEncoder_columns_list = ['sshydm', 'tyshxydm', 'zczbbzmc', 'hymldm', 'zsszdsf', 'fzhyml', 'xxtgbmmc', 'zl', 'sszj', 'fzjgmc', 'qyjglxmc', 'qylxmc', \n",
    "                            'QYFZCHRD_swglm', 'QYFZCHRD_gljg', 'QYFZCHRD_djzclx', \n",
    "                            'SGSFRXZXKXX_xknr', 'SGSFRXZXKXX_xmmc', 'SGSFRXZXKXX_splb', 'SGSFRXZXKXX_xkjg', 'SGSFRXZXKXX_xysyfw', 'SGSFRXZXKXX_sjzt2', \n",
    "                            'XKZZNJXX_njnd', 'XKZZNJXX_njjgmc', 'XKZZNJXX_njsxmc', \n",
    "                            'ZZDJBGXX_zzmc', 'ZZDJBGXX_zyfw', 'ZZDJBGXX_rdjgqc', 'ZZDJBGXX_zzzsbh', \n",
    "                            'jgdzzs', 'jyfw', 'sshymc', 'fzrq', 'bghzrq', 'gszch', 'fddbrzjhm', 'zzjgdm', \n",
    "                            'SGSFRXZXKXX_xzxkbm', 'SGSFRXZXKXX_xkjdswh', 'SGSFRXZXKXX_xxtgbmmc', 'XKZZNJXX_xxtgbmmc',\n",
    "                            'QYFZCHRD_rwbh', 'QYFZCHRD_zcdz', 'QYFZCHRD_xxtgbmmc', \n",
    "                             'jgdzzs_top3', 'jgdzzs_top6', \n",
    "                            'QYSWDJXX_fddbrzjmc', 'QYSWDJXX_shdw', 'QYSWDJXX_qy', 'QYSWDJXX_shjg', 'QYSWDJXX_djzclx', ]\n",
    "\n",
    "# for feat in labelEncoder_columns_list:\n",
    "#     col_encoder = LabelEncoder()\n",
    "#     try:\n",
    "#         temp_df[feat + '_encoder'] = col_encoder.fit_transform(temp_df[feat])\n",
    "#     except:\n",
    "#         temp_df[feat + '_encoder'] = col_encoder.fit_transform(temp_df[feat].fillna('nan'))\n",
    "#     train_df = pd.merge(train_df, temp_df[['qymc', feat + '_encoder']], on='qymc', how='left')\n",
    "#     test_df = pd.merge(test_df, temp_df[['qymc', feat + '_encoder']], on='qymc', how='left')\n",
    "#     print(feat + \" finish!!!\")\n",
    "\n",
    "def get_type_future_encoder(train_df, test_df, col_name):\n",
    "    df_copy = pd.concat([train_df[[col_name]], test_df[[col_name]]])\n",
    "    df_copy[col_name] = df_copy[col_name].astype(str)\n",
    "    df_copy.sort_values(by = col_name, inplace = True)\n",
    "    df_copy.drop_duplicates([col_name], inplace = True)\n",
    "    df_copy.reset_index(inplace = True)\n",
    "    df_copy[col_name + '_encoder'] = df_copy.index\n",
    "    train_df = pd.merge(train_df, df_copy[[col_name, col_name + '_encoder']], on=col_name, how='left')\n",
    "    test_df = pd.merge(test_df, df_copy[[col_name, col_name + '_encoder']], on=col_name, how='left')\n",
    "    return train_df, test_df\n",
    "\n",
    "for fea in labelEncoder_columns_list:\n",
    "    train_df, test_df = get_type_future_encoder(train_df, test_df, fea)\n",
    "    print(fea + \" finish!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导出预测结果\n",
    "def exportDf(df, fileName):\n",
    "    df.to_csv('../temp/%s.csv' % fileName, header=True, index=False)\n",
    "    \n",
    "exportDf(train_df, 'fusai_train_df_all')\n",
    "exportDf(test_df, 'fusai_test_df_all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
